

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>启动基于kafka的排序服务(Bringing up a Kafka-based Ordering Service) &mdash; hyperledger-fabricdocs master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Commands Reference" href="command_ref.html" />
    <link rel="prev" title="Securing Communication With Transport Layer Security (TLS)" href="enable_tls.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          


          
            <a href="index.html" class="icon icon-home"> hyperledger-fabricdocs
          

          
          </a>

          
            
            
              <div class="version">
                master
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
<br>
<a href="https://chat.hyperledger.org">Rocket Chat</a>  <a href="https://jenkins.hyperledger.org/">CI</a>
<a href="http://stackoverflow.com/questions/tagged/hyperledger-fabric">StackOverflow</a>
<br>
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
  <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
  <br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">欢迎来到 Hyperledger Fabric</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="getting_started.html">入门指南</a></li>
<li class="toctree-l2"><a class="reference internal" href="key_concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials.html">Tutorials - 教程</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="ops_guide.html">Operations Guides</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="upgrade_to_one_point_one.html">Upgrading from v1.0.x</a></li>
<li class="toctree-l3"><a class="reference internal" href="config_update.html">Updating a Channel Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="msp.html">Membership Service Providers (MSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="msp.html#msp">成员服务提供者 （MSP）</a></li>
<li class="toctree-l3"><a class="reference internal" href="configtx.html">Channel Configuration (configtx)</a></li>
<li class="toctree-l3"><a class="reference internal" href="endorsement-policies.html">Endorsement policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="error-handling.html">Error handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="logging-control.html">Logging Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="enable_tls.html">Securing Communication With Transport Layer Security (TLS)</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">启动基于kafka的排序服务(Bringing up a Kafka-based Ordering Service)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#caveat-emptor">须知(Caveat emptor)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#big-picture">概览(Big picture)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#steps">步骤(Steps)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#additional-considerations">其他注意事项(Additional considerations)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kafka-kafka-protocol-version-compatibility">支持的 Kafka 版本和升级(Kafka Protocol Version Compatibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#debugging">调试(Debugging)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example">例子(Example)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="command_ref.html">Commands Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html">架构参考</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fabric-FAQ.html">Hyperledger Fabric FAQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="ordering-service-faq.html">Ordering Service FAQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="CONTRIBUTING.html">Contributions Welcome!</a></li>
<li class="toctree-l2"><a class="reference internal" href="glossary.html">Glossary - 词汇表</a></li>
<li class="toctree-l2"><a class="reference internal" href="releases.html">Release Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="questions.html">Still Have Questions? - 依然遇到问题？</a></li>
<li class="toctree-l2"><a class="reference internal" href="status.html">Status - 状态</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">入门指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html">Key Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials - 教程</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="ops_guide.html">Operations Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="upgrade_to_one_point_one.html">Upgrading from v1.0.x</a></li>
<li class="toctree-l2"><a class="reference internal" href="config_update.html">Updating a Channel Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="msp.html">Membership Service Providers (MSP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="msp.html#msp">成员服务提供者 （MSP）</a></li>
<li class="toctree-l2"><a class="reference internal" href="configtx.html">Channel Configuration (configtx)</a></li>
<li class="toctree-l2"><a class="reference internal" href="endorsement-policies.html">Endorsement policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="error-handling.html">Error handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging-control.html">Logging Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="enable_tls.html">Securing Communication With Transport Layer Security (TLS)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">启动基于kafka的排序服务(Bringing up a Kafka-based Ordering Service)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#caveat-emptor">须知(Caveat emptor)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#big-picture">概览(Big picture)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#steps">步骤(Steps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#additional-considerations">其他注意事项(Additional considerations)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kafka-kafka-protocol-version-compatibility">支持的 Kafka 版本和升级(Kafka Protocol Version Compatibility)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging">调试(Debugging)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">例子(Example)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="command_ref.html">Commands Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构参考</a></li>
<li class="toctree-l1"><a class="reference internal" href="Fabric-FAQ.html">Hyperledger Fabric FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordering-service-faq.html">Ordering Service FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributions Welcome!</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary - 词汇表</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="questions.html">Still Have Questions? - 依然遇到问题？</a></li>
<li class="toctree-l1"><a class="reference internal" href="status.html">Status - 状态</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">hyperledger-fabricdocs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="ops_guide.html">Operations Guides</a> &raquo;</li>
        
      <li>启动基于kafka的排序服务(Bringing up a Kafka-based Ordering Service)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/kafka.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="kafka-bringing-up-a-kafka-based-ordering-service">
<h1>启动基于kafka的排序服务(Bringing up a Kafka-based Ordering Service)<a class="headerlink" href="#kafka-bringing-up-a-kafka-based-ordering-service" title="Permalink to this headline">¶</a></h1>
<div class="section" id="caveat-emptor">
<span id="kafka-caveat"></span><h2>须知(Caveat emptor)<a class="headerlink" href="#caveat-emptor" title="Permalink to this headline">¶</a></h2>
<p>This document assumes that the reader generally knows how to set up a Kafka cluster and a ZooKeeper ensemble. The purpose of this guide is to identify the steps you need to take so as to have a set of Hyperledger Fabric ordering service nodes (OSNs) use your Kafka cluster and provide an ordering service to your blockchain network.</p>
<p>该文档假设读者已经基本了解如何去搭建Kafka集群和ZooKeeper集群。本文档的目的是跟您确认有关使用Kafka集群搭建一套为你的区块链网络提供排序服务的Hyperledger Fabric排序服务节点集(OSNs)所需要采取的步骤。。</p>
</div>
<div class="section" id="big-picture">
<h2>概览(Big picture)<a class="headerlink" href="#big-picture" title="Permalink to this headline">¶</a></h2>
<p>Each channel maps to a separate single-partition topic in Kafka. When an OSN receives transactions via the <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> RPC, it checks to make sure that the broadcasting client has permissions to write on the channel, then relays (i.e. produces) those transactions to the appropriate partition in Kafka. This partition is also consumed by the OSN which groups the received transactions into blocks locally, persists them in its local ledger, and serves them to receiving clients via the <code class="docutils literal notranslate"><span class="pre">Deliver</span></code> RPC. For low-level details, refer to <a class="reference external" href="https://docs.google.com/document/d/1vNMaM7XhOlu9tB_10dKnlrhy5d7b1u8lSY8a-kVjCO4/edit">the document that describes how we came to this design</a> — Figure 8 is a schematic representation of the process described above.</p>
<p>每一个通道(channel)在Kafka中被映射到一个单独的单分区(partition)类别(topic)。当排序节点接收到客户端通过RPC广播(Broadcast)出来的交易时，它会检查广播交易的客户端是否有权限去修改通道(channel)数据，然后反馈（即产生）这些交易到Kafka的适当分区(partition)中。该分区也被排序节点所消费(consume)(译者注：生产者消费者模型)，排序节点将接收到的交易在本地分组后打包进区块，将其持久化在本地账本中，并通过Deliver RPC提供给需要接收的客户端。更多详细的信息，请参考the document that describes how we came to this design &lt;<a class="reference external" href="https://docs.google.com/document/d/1vNMaM7XhOlu9tB_10dKnlrhy5d7b1u8lSY8a-kVjCO4/edit">https://docs.google.com/document/d/1vNMaM7XhOlu9tB_10dKnlrhy5d7b1u8lSY8a-kVjCO4/edit</a>&gt;_ – 图8是上述过程的示意图。</p>
</div>
<div class="section" id="steps">
<h2>步骤(Steps)<a class="headerlink" href="#steps" title="Permalink to this headline">¶</a></h2>
<p>Let <code class="docutils literal notranslate"><span class="pre">K</span></code> and <code class="docutils literal notranslate"><span class="pre">Z</span></code> be the number of nodes in the Kafka cluster and the ZooKeeper ensemble respectively:</p>
<p>设定变量 K 和 Z 分别是Kafka集群和ZooKeeper集群的节点数量：</p>
<ol class="arabic">
<li><p class="first">At a minimum, <code class="docutils literal notranslate"><span class="pre">K</span></code> should be set to 4. (As we will explain in Step 4 below,  this is the minimum number of nodes necessary in order to exhibit crash fault tolerance, i.e. with 4 brokers, you can have 1 broker go down, all channels will continue to be writeable and readable, and new channels can be created.)</p>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">Z</span></code> will either be 3, 5, or 7. It has to be an odd number to avoid split-brain scenarios, and larger than 1 in order to avoid single point of failures. Anything beyond 7 ZooKeeper servers is considered an overkill.</p>
<p>设K的最小值需要是4。(我们将在步骤4中解释，这是实现 故障容错(crash fault tolerance) 所需要的最小数值，也就是说， 4个节点可以容许1个节点宕机，所有的通道能够继续读写且可以创建通道。)(译者：Kafka节点被称为broker)
Z可以是3、5或者7。它必须是一个奇数来避免分裂(split-brain)情景，大于1以避免单点故障。 超过7个ZooKeeper服务器则被认为是多余的。</p>
</li>
</ol>
<p>Then proceed as follows:</p>
<p>请按照以下步骤进行:</p>
<ol class="arabic" start="3">
<li><p class="first">Orderers: <strong>Encode the Kafka-related information in the network’s genesis block.</strong> If you are using <code class="docutils literal notranslate"><span class="pre">configtxgen</span></code>, edit <code class="docutils literal notranslate"><span class="pre">configtx.yaml</span></code> —or pick a preset profile for the system channel’s genesis block—  so that:</p>
<p>Orderers: <strong>Kafka 相关信息被写在网络的初始区块中</strong>. 如果你使用 <code class="docutils literal notranslate"><span class="pre">configtxgen</span></code> 工具, 编辑 <code class="docutils literal notranslate"><span class="pre">configtx.yaml</span></code> 文件– 或者挑一个现成的系统通道的初始区块配置文件 – 其中:</p>
<ol class="arabic">
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">Orderer.OrdererType</span></code> is set to <code class="docutils literal notranslate"><span class="pre">kafka</span></code>.</p>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">Orderer.Kafka.Brokers</span></code> contains the address of <em>at least two</em> of the Kafka brokers in your cluster in <code class="docutils literal notranslate"><span class="pre">IP:port</span></code> notation. The list does not need to be exhaustive. (These are your bootstrap brokers.)</p>
<p><code class="docutils literal notranslate"><span class="pre">Orderer.OrdererType</span></code> 字段被设置为 <code class="docutils literal notranslate"><span class="pre">kafka</span></code>.
<code class="docutils literal notranslate"><span class="pre">Orderer.Kafka.Brokers</span></code> 字段包含*至少两个* Kafka集群中的节点 <code class="docutils literal notranslate"><span class="pre">IP:port</span></code> 样式的地址。这个列表没有必要详尽无遗(这些是你的引导 brokers.)</p>
</li>
</ol>
</li>
<li><p class="first">Orderers: <strong>Set the maximum block size.</strong> Each block will have at most <cite>Orderer.AbsoluteMaxBytes</cite> bytes (not including headers), a value that you can set in <code class="docutils literal notranslate"><span class="pre">configtx.yaml</span></code>. Let the value you pick here be <code class="docutils literal notranslate"><span class="pre">A</span></code> and make note of it — it will affect how you configure your Kafka brokers in Step 6.</p>
</li>
<li><p class="first">Orderers: <strong>Create the genesis block.</strong> Use <code class="docutils literal notranslate"><span class="pre">configtxgen</span></code>. The settings you picked in Steps 3 and 4 above are system-wide settings, i.e. they apply across the network for all the OSNs. Make note of the genesis block’s location.</p>
</li>
<li><p class="first">Kafka cluster: <strong>Configure your Kafka brokers appropriately.</strong> Ensure that every Kafka broker has these keys configured:</p>
<p>Orderers: <strong>设置区块最大容量.</strong> 每一个区块最多只能有 <cite>Orderer.AbsoluteMaxBytes</cite> 字节的容量(不含区块头信息), 这是一个你可以修改的值，存放在 <code class="docutils literal notranslate"><span class="pre">configtx.yaml</span></code> 配置文件中. 假设此处你设置的数值为``A``,将此数字记下来 – 这会影响你在步骤6中对于Kafka brokers 的配置.
Orderers: 使用 <code class="docutils literal notranslate"><span class="pre">configtxgen</span></code> 工具 <strong>创建初始区块.</strong> 在步骤3和4中的设置是全局的设置, 也就是说这些设置的生效范围是网络中所有的排序节点. 记录下初始区块的位置.
Kafka 集群: <strong>适当配置你的Kafka集群.</strong> 确保每一个Kafka节点都配置了以下的值:</p>
<ol class="arabic">
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">unclean.leader.election.enable</span> <span class="pre">=</span> <span class="pre">false</span></code> — Data consistency is key in a blockchain environment. We cannot have a channel leader chosen outside of the in-sync replica set, or we run the risk of overwriting the offsets that the previous leader produced, and —as a result— rewrite the blockchain that the orderers produce.</p>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">min.insync.replicas</span> <span class="pre">=</span> <span class="pre">M</span></code> — Where you pick a value <code class="docutils literal notranslate"><span class="pre">M</span></code> such that <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">&lt;</span> <span class="pre">M</span> <span class="pre">&lt;</span> <span class="pre">N</span></code> (see <code class="docutils literal notranslate"><span class="pre">default.replication.factor</span></code> below). Data is considered committed when it is written to at least <code class="docutils literal notranslate"><span class="pre">M</span></code> replicas (which are then considered in-sync and belong to the in-sync replica set, or ISR). In any other case, the write operation returns an error. Then:</p>
<p><code class="docutils literal notranslate"><span class="pre">unclean.leader.election.enable</span> <span class="pre">=</span> <span class="pre">false</span></code> – 数据一致性是区块链环境的关键. 我们不能选择不在同步副本集中的channel leader, 也不能冒风险去覆盖前一leader所产生的偏移量, 那样的结果就是重写orderers所产生的区块链数据.
<code class="docutils literal notranslate"><span class="pre">min.insync.replicas</span> <span class="pre">=</span> <span class="pre">M</span></code> – <code class="docutils literal notranslate"><span class="pre">M</span></code> 的值需要满足 <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">&lt;</span> <span class="pre">M</span> <span class="pre">&lt;</span> <span class="pre">N</span></code> (N的值参考后面的 <code class="docutils literal notranslate"><span class="pre">default.replication.factor</span></code>). 数据被认为是完成提交当它被写入到至少 <code class="docutils literal notranslate"><span class="pre">M</span></code> 个副本中(也就是说它被认为是同步的,然后被写入到同步副本集中,也成为ISR). 其他情况, 写入操作返回错误信息. 然后:</p>
<ol class="arabic">
<li><p class="first">If up to <code class="docutils literal notranslate"><span class="pre">N-M</span></code> replicas —out of the <code class="docutils literal notranslate"><span class="pre">N</span></code> that the channel data is written to— become unavailable, operations proceed normally.</p>
</li>
<li><p class="first">If more replicas become unavailable, Kafka cannot maintain an ISR set of <code class="docutils literal notranslate"><span class="pre">M,</span></code> so it stops accepting writes. Reads work without issues. The channel becomes writeable again when <code class="docutils literal notranslate"><span class="pre">M</span></code> replicas get in-sync.</p>
<p>如果有 <code class="docutils literal notranslate"><span class="pre">N-M</span></code> 个副本不可访问, 操作将正常进行.
如果更多副本不可访问, Kafka 不能位置数量 <code class="docutils literal notranslate"><span class="pre">M</span></code> 的同步副本集(ISR), 所以它会停止接受写入操作. 读操作可以正常运行. 当``M``个副本重新同步后,通道就可以再次变为可写入状态.</p>
</li>
</ol>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">default.replication.factor</span> <span class="pre">=</span> <span class="pre">N</span></code> — Where you pick a value <code class="docutils literal notranslate"><span class="pre">N</span></code> such that <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">&lt;</span> <span class="pre">K</span></code>. A replication factor of <code class="docutils literal notranslate"><span class="pre">N</span></code> means that each channel will have its data replicated to <code class="docutils literal notranslate"><span class="pre">N</span></code> brokers. These are the candidates for the ISR set of a channel. As we noted in the <code class="docutils literal notranslate"><span class="pre">min.insync.replicas</span> <span class="pre">section</span></code> above, not all of these brokers have to be available all the time. <code class="docutils literal notranslate"><span class="pre">N</span></code> should be set <em>strictly smaller</em> to <code class="docutils literal notranslate"><span class="pre">K</span></code> because channel creations cannot go forward if less than <code class="docutils literal notranslate"><span class="pre">N</span></code> brokers are up. So if you set <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">K</span></code>, a single broker going down means that no new channels can be created on the blockchain network — the crash fault tolerance of the ordering service is non-existent.</p>
<p><code class="docutils literal notranslate"><span class="pre">default.replication.factor</span> <span class="pre">=</span> <span class="pre">N</span></code> – 选择一个 <code class="docutils literal notranslate"><span class="pre">N</span></code> 的数值满足 <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">&lt;</span> <span class="pre">K</span></code> (Kafak集群数量). 参数 <code class="docutils literal notranslate"><span class="pre">N</span></code> 表示每个channel 的数据会复制到 <code class="docutils literal notranslate"><span class="pre">N</span></code> 个 broker 中. 这些是 channel 同步副本集的候选. 正如前面 <code class="docutils literal notranslate"><span class="pre">min.insync.replicas</span></code> 部分所说的, 不是所有broker都需要是随时可用的. N 值需要设置为绝对小于 <code class="docutils literal notranslate"><span class="pre">K</span></code> , 因为channel的创建需要不少于 <code class="docutils literal notranslate"><span class="pre">N</span></code> 个broker是启动的. 所以如果设置 <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">K</span></code> , 一个 broker 宕机就意味着区块链网络不能再创建channel. 那么故障容错的排序服务也就不存在了.</p>
<p>Based on what we’ve described above, the minimum allowed values for <code class="docutils literal notranslate"><span class="pre">M</span></code> and <code class="docutils literal notranslate"><span class="pre">N</span></code> are 2 and 3 respectively. This configuration allows for the creation of new channels to go forward, and for all channels to continue to be writeable.</p>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">message.max.bytes</span></code> and <code class="docutils literal notranslate"><span class="pre">replica.fetch.max.bytes</span></code> should be set to a value larger than <code class="docutils literal notranslate"><span class="pre">A</span></code>, the value you picked in <code class="docutils literal notranslate"><span class="pre">Orderer.AbsoluteMaxBytes</span></code> in Step 4 above. Add some buffer to account for headers — 1 MiB is more than enough. The following condition applies:</p>
<p>基于我们上述的描述，<code class="docutils literal notranslate"><span class="pre">M</span></code> 和 <code class="docutils literal notranslate"><span class="pre">N</span></code> 允许的最小值分别是2和3，这种配置使得继续创建新通道，以及让所有通道可写入。
<code class="docutils literal notranslate"><span class="pre">message.max.bytes</span></code> 和 <code class="docutils literal notranslate"><span class="pre">replica.fetch.max.bytes</span></code> 的值需要大于 <code class="docutils literal notranslate"><span class="pre">A</span></code>, 就是在步骤4中选取的 <code class="docutils literal notranslate"><span class="pre">Orderer.AbsoluteMaxBytes</span></code> 的值. 再为区块头增加一些余量 – 1 MiB 就足够了. 需要满足以下条件:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Orderer</span><span class="o">.</span><span class="n">AbsoluteMaxBytes</span> <span class="o">&lt;</span> <span class="n">replica</span><span class="o">.</span><span class="n">fetch</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">bytes</span> <span class="o">&lt;=</span> <span class="n">message</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">bytes</span>
</pre></div>
</div>
<p>(For completeness, we note that <code class="docutils literal notranslate"><span class="pre">message.max.bytes</span></code> should be strictly smaller to <code class="docutils literal notranslate"><span class="pre">socket.request.max.bytes</span></code> which is set by default to 100 MiB. If you wish to have blocks larger than 100 MiB you will need to edit the hard-coded value in <code class="docutils literal notranslate"><span class="pre">brokerConfig.Producer.MaxMessageBytes</span></code> in <code class="docutils literal notranslate"><span class="pre">fabric/orderer/kafka/config.go</span></code> and rebuild the binary from source. This is not advisable.)</p>
<p>(补充, 我们注意到 <code class="docutils literal notranslate"><span class="pre">message.max.bytes</span></code> 需要严格小于 <code class="docutils literal notranslate"><span class="pre">socket.request.max.bytes</span></code> , 这个值默认是100Mib. 如果你希望区块大于100MiB, 你需要去修改硬代码中的变量 <code class="docutils literal notranslate"><span class="pre">brokerConfig.Producer.MaxMessageBytes</span></code> , 代码位置是 <code class="docutils literal notranslate"><span class="pre">fabric/orderer/kafka/config.go</span></code> , 再重新编译代码, 不建议这么做.)</p>
</li>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">log.retention.ms</span> <span class="pre">=</span> <span class="pre">-1</span></code>. Until the ordering service adds support for pruning of the Kafka logs, you should disable time-based retention and prevent segments from expiring. (Size-based retention —see <code class="docutils literal notranslate"><span class="pre">log.retention.bytes</span></code>— is disabled by default in Kafka at the time of this writing, so there’s no need to set it explicitly.)</p>
<p><code class="docutils literal notranslate"><span class="pre">log.retention.ms</span> <span class="pre">=</span> <span class="pre">-1</span></code>. 直到排序服务增加了对于 Kafka 日志分割(pruning)的支持之前, 应该禁用基于时间分割的方式以避免单个日志文件到期分段. (基于文件大小的分割方式 – 看参数 <code class="docutils literal notranslate"><span class="pre">log.retention.bytes</span></code> – 在本文书写时, 在 Kafka 中是默认被禁用的, 所以这个值没有必要指定地很明确. )</p>
</li>
</ol>
</li>
<li><p class="first">Orderers: <strong>Point each OSN to the genesis block.</strong> Edit <code class="docutils literal notranslate"><span class="pre">General.GenesisFile</span></code> in <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> so that it points to the genesis block created in Step 5 above. (While at it, ensure all other keys in that YAML file are set appropriately.)</p>
</li>
<li><p class="first">Orderers: <strong>Adjust polling intervals and timeouts.</strong> (Optional step.)</p>
<p>Orderers: <strong>将所有排序节点指向初始区块.</strong> 编辑 <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span> <span class="pre">``文件中的参数</span> <span class="pre">``General.GenesisFile</span></code> 使其指向步骤3中所创建的初始区块. (同时, 确保YAML文件中所有其他参数都是正确的.)
Orderers: <a href="#id1"><span class="problematic" id="id2">**</span></a>调整轮询间隔和超时时间. <a href="#id3"><span class="problematic" id="id4">**</span></a>(可选步骤.)</p>
<ol class="arabic">
<li><p class="first">The <code class="docutils literal notranslate"><span class="pre">Kafka.Retry</span></code> section in the <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> file allows you to adjust the frequency of the metadata/producer/consumer requests, as well as the socket timeouts. (These are all settings you would expect to see in a Kafka producer or consumer.)</p>
</li>
<li><p class="first">Additionally, when a new channel is created, or when an existing channel is reloaded (in case of a just-restarted orderer), the orderer interacts with the Kafka cluster in the following ways:</p>
<p><code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> 文件中的 <code class="docutils literal notranslate"><span class="pre">Kafka.Retry</span></code> 区域让你能够调整 metadata/producer/consumer 请求的频率以及socket的超时时间. (这些应该就是所有在 kafka 的生产者和消费者 中你需要的设置)
另外, 当一个 channel 被创建, 或当一个现有的 channel 被重新读取(刚启动 orderer 的情况), orderer 通过以下方式和 Kafka 集群进行交互.</p>
<ol class="arabic">
<li><p class="first">It creates a Kafka producer (writer) for the Kafka partition that corresponds to the channel.</p>
</li>
<li><p class="first">It uses that producer to post a no-op <code class="docutils literal notranslate"><span class="pre">CONNECT</span></code> message to that partition.</p>
</li>
<li><p class="first">It creates a Kafka consumer (reader) for that partition.</p>
<p>为 channel 对应的 Kafka 分区 创建一个 Kafka 生产者.
通过生产者向这个分区发一个空的 <a href="#id5"><span class="problematic" id="id6">``</span></a>CONNECT``信息.
为这个分区创建一个 Kafka 消费者.</p>
</li>
</ol>
<p>If any of these steps fail, you can adjust the frequency with which they are repeated. Specifically they will be re-attempted every <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.ShortInterval</span></code> for a total of <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.ShortTotal</span></code>, and then every <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.LongInterval</span></code> for a total of <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.LongTotal</span></code> until they succeed. Note that the orderer will be unable to write to or read from a channel until all of the steps above have been completed successfully.
如果任意步骤出错, 你可以调整其重复的频率.这些步骤会在每一个 <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.ShortInterval</span></code> 指定的时间间隔后进行重试 <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.ShortTotal</span></code> 次,再以 <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.LongInterval</span></code> 规定的时间间隔重试 <code class="docutils literal notranslate"><span class="pre">Kafka.Retry.LongTotal</span></code> 次直到成功.需要注意的是 orderer 不能读写该 channel 的数据直到所有上述步骤都成功执行.</p>
</li>
</ol>
</li>
<li><p class="first"><strong>Set up the OSNs and Kafka cluster so that they communicate over SSL.</strong> (Optional step, but highly recommended.) Refer to <a class="reference external" href="http://docs.confluent.io/2.0.0/kafka/ssl.html">the Confluent guide</a> for the Kafka cluster side of the equation, and set the keys under <code class="docutils literal notranslate"><span class="pre">Kafka.TLS</span></code> in <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> on every OSN accordingly.</p>
</li>
<li><p class="first"><strong>Bring up the nodes in the following order: ZooKeeper ensemble, Kafka cluster, ordering service nodes.</strong></p>
<p><strong>将排序节点和 Kafka 集群间设置为通过 SSL 通讯.</strong> (可选步骤,强烈推荐) 参考 <a class="reference external" href="http://docs.confluent.io/2.0.0/kafka/ssl.html">the Confluent guide</a> 文档中关于 Kafka 集群的设置, 来设置每个排序节点 <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> 文件中 <code class="docutils literal notranslate"><span class="pre">Kafka.TLS</span></code> 部分的内容.
<strong>启动节点请按照以下顺序: ZooKeeper 集群, Kafka 集群, 排序节点</strong></p>
</li>
</ol>
</div>
<div class="section" id="additional-considerations">
<h2>其他注意事项(Additional considerations)<a class="headerlink" href="#additional-considerations" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first"><strong>Preferred message size.</strong> In Step 4 above (see <a href="#id11"><span class="problematic" id="id12">`Steps`_</span></a> section) you can also set the preferred size of blocks by setting the <code class="docutils literal notranslate"><span class="pre">Orderer.Batchsize.PreferredMaxBytes</span></code> key. Kafka offers higher throughput when dealing with relatively small messages; aim for a value no bigger than 1 MiB.</p>
</li>
<li><p class="first"><strong>Using environment variables to override settings.</strong> When using the sample Kafka and Zookeeper Docker images provided with Fabric (see <code class="docutils literal notranslate"><span class="pre">images/kafka</span></code> and <code class="docutils literal notranslate"><span class="pre">images/zookeeper</span></code> respectively), you can override a Kafka broker or a ZooKeeper server’s settings by using environment variables. Replace the dots of the configuration key with underscores — e.g. <code class="docutils literal notranslate"><span class="pre">KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false</span></code> will allow you to override the default value of <code class="docutils literal notranslate"><span class="pre">unclean.leader.election.enable</span></code>. The same applies to the OSNs for their <em>local</em> configuration, i.e. what can be set in <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code>. For example <code class="docutils literal notranslate"><span class="pre">ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s</span></code> allows you to override the default value for <code class="docutils literal notranslate"><span class="pre">Orderer.Kafka.Retry.ShortInterval</span></code>.</p>
<p><strong>首选的消息大小.</strong> 在上面的步骤4中, 你也能通过参数 <code class="docutils literal notranslate"><span class="pre">Orderer.Batchsize.PreferredMaxBytes</span></code> 设置首选的区块大小. Kafka 处理相对较小的信息有更高的吞吐量; 针对小于 1 MiB 大小的值.
<strong>使用环境变量重写设置.</strong> 当使用Fabric提供的Kafka和Zookeeper的Docker镜像样例时(分别查看 <code class="docutils literal notranslate"><span class="pre">images/kafka</span></code> 和 <code class="docutils literal notranslate"><span class="pre">images/zookeeper</span></code> )，你能够通过设置环境变量来重写 Kafka 节点和 Zookeeper 服务器的设置. 替换配置参数中的 点 为 下划线 – 例如 <code class="docutils literal notranslate"><span class="pre">KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false</span></code> 环境变量重写配置参数 <code class="docutils literal notranslate"><span class="pre">unclean.leader.election.enable</span></code>. 环境变量重写同样适用于排序节点的本地配置, 即 <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> 中所能设置的. 例如 <code class="docutils literal notranslate"><span class="pre">ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s</span></code> 环境变量可以重写本地配置文件中的 <code class="docutils literal notranslate"><span class="pre">Orderer.Kafka.Retry.ShortInterval</span></code>.</p>
</li>
</ol>
</div>
<div class="section" id="kafka-kafka-protocol-version-compatibility">
<h2>支持的 Kafka 版本和升级(Kafka Protocol Version Compatibility)<a class="headerlink" href="#kafka-kafka-protocol-version-compatibility" title="Permalink to this headline">¶</a></h2>
<p>Fabric uses the <a class="reference external" href="https://github.com/Shopify/sarama">sarama client library</a> and vendors a version of it that supports Kafka 0.10 to 1.0, yet is still known to work with older versions.</p>
<p>Fabric 使用代码库: <a href="#id8"><span class="problematic" id="id9">``</span></a>sarama client library &lt;<a class="reference external" href="https://github.com/Shopify/sarama">https://github.com/Shopify/sarama</a>&gt;``_ 支持的 Kafka 版本是 0.10 到 1.0，并且在更老的版本上依然可以工作。</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">Kafka.Version</span></code> key in <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code>, you can configure which version of the Kafka protocol is used to communicate with the Kafka cluster’s brokers. Kafka brokers are backward compatible with older protocol versions. Because of a Kafka broker’s backward compatibility with older protocol versions, upgrading your Kafka brokers to a new version does not require an update of the <code class="docutils literal notranslate"><span class="pre">Kafka.Version</span></code> key value, but the Kafka cluster might suffer a <a class="reference external" href="https://kafka.apache.org/documentation/#upgrade_11_message_format">performance penalty</a> while using an older protocol version.</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">Kafka.Version</span></code> ，你可以配置Kafka 集群节点用于交流的 Kafka协议的版本。Kafka brokers向前兼容更老的协议版本。 由于Kafka brokers向前兼容更老的协议版本，升级你的Kafka brokers到一个新的版本不需要更新 <code class="docutils literal notranslate"><span class="pre">Kafka.Version</span></code> 的值，但是Kafka集群在使用一个更老的版本时可能需要忍受 <a class="reference external" href="https://kafka.apache.org/documentation/#upgrade_11_message_format">performance penalty</a></p>
</div>
<div class="section" id="debugging">
<h2>调试(Debugging)<a class="headerlink" href="#debugging" title="Permalink to this headline">¶</a></h2>
<p>Set <code class="docutils literal notranslate"><span class="pre">General.LogLevel</span></code> to <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code> and <code class="docutils literal notranslate"><span class="pre">Kafka.Verbose</span></code> in <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<p>设置 <code class="docutils literal notranslate"><span class="pre">orderer.yaml</span></code> 文件中 <code class="docutils literal notranslate"><span class="pre">General.LogLevel</span></code> 为 <code class="docutils literal notranslate"><span class="pre">DEBUG</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Kafka.Verbose</span></code> 为 <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</div>
<div class="section" id="example">
<h2>例子(Example)<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>Sample Docker Compose configuration files inline with the recommended settings above can be found under the <code class="docutils literal notranslate"><span class="pre">fabric/bddtests</span></code> directory. Look for <code class="docutils literal notranslate"><span class="pre">dc-orderer-kafka-base.yml</span></code> and <code class="docutils literal notranslate"><span class="pre">dc-orderer-kafka.yml</span></code>.</p>
<p>包含了推荐的设置的Docker Compose 配置文件示例能够在 <code class="docutils literal notranslate"><span class="pre">fabric/bddtests</span></code> 目录中找到. 包括 <code class="docutils literal notranslate"><span class="pre">dc-orderer-kafka-base.yml</span></code> 文件和 <code class="docutils literal notranslate"><span class="pre">dc-orderer-kafka.yml</span></code> 文件.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="command_ref.html" class="btn btn-neutral float-right" title="Commands Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="enable_tls.html" class="btn btn-neutral" title="Securing Communication With Transport Layer Security (TLS)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Hyperledger 2017.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'master',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>